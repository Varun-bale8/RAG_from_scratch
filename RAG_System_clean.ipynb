{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwkOWgKxVxIu",
    "outputId": "314da89a-d5dd-44b6-8956-3c94dec4e912"
   },
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers faiss-cpu langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fadaG7ZV4Az",
    "outputId": "c8d083e7-b048-4648-a416-45a8ce0c2176"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load our document\n",
    "with open(\"/content/myknowledge.txt\") as f:\n",
    "    knowledge_text = f.read()\n",
    "\n",
    "# 1. Initialize the Text Splitter\n",
    "# This splitter is smart. It tries to split on paragraphs (\"\\n\\n\"),\n",
    "# then newlines (\"\\n\"), then spaces (\" \"), to keep semantically\n",
    "# related text together as much as possible.\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,  # Max size of a chunk\n",
    "    chunk_overlap=20, # Overlap to maintain context between chunks\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# 2. Create the chunks\n",
    "chunks = text_splitter.split_text(knowledge_text)\n",
    "\n",
    "print(f\"We have {len(chunks)} chunks:\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"--- Chunk {i+1} ---\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515,
     "referenced_widgets": [
      "6943c280cf6d4641ad23f5f921e45571",
      "081b389a01af421c8e65b6d4082a6df4",
      "5d45467a57084eb2bc216aeb1abb3f66",
      "ae581729343b42dca1143ff2ddba700b",
      "00acdf76adb045728fa1d6b80db1a8ed",
      "b6728128ceba4dd498d371d3e5c02125",
      "501f049f9d9343e398f76ab388c6b769",
      "2511834ad4d44f20bcd8ff760607f145",
      "25d08bf3d2b6497c92823537249ed86e",
      "7800152f589b41adb0e5d99ca35d9ef9",
      "feb3aaffd0d44ea999926ac67f7719a1",
      "d226efe5738c4359af4a568cdab2acea",
      "b1f4b517800648a99fd865f1fa93d561",
      "f90ba28d10a8498ca5f407026f3ae1fb",
      "cbe818a0fd9841cdb36c940b597a4ad1",
      "5c8adf3ca5d94d08b5ce5248f55e15b5",
      "54c6437c9fca4fb89afc28f252a3caa6",
      "319ce4581f384d01b3afc9e4623ce8fe",
      "f1836f681e624caca576aecb2148515d",
      "c1d44794a7af420aa957b6dd09c9fead",
      "1d89742813734fc9af76dace7d4664ab",
      "37c0d1b1c1f04526b942e44e3c18aea0",
      "01c5d64160fd4d5e9fc1c8a731589e5b",
      "b700407cbd3a4f10a5a9ec068b6b0487",
      "9ae12cb99eba48dd8e818864309e779b",
      "a7887becb0404256a9332b960906d647",
      "620bdd556d114a9e86c287ba859199e3",
      "c5ec66dea1be43c29ab39416af3376a9",
      "76cfeaf4347b4ffa96e2b2e6b9c7513c",
      "be56b20884924a8d9510f1500c5efdd0",
      "3b4f4259c36d4b6b8b16101ceb217c10",
      "dcf728a2d77a44858c5a62e269adf740",
      "076b1ca132984f04a0b45e66a959921d",
      "c4f4a8bc0afd4ac796b12cc42adccdc8",
      "d8a2ed7ac1234d1fb95841862846c233",
      "d5265e5058164adb96abb2ec9d7091f1",
      "715d385ad5754864ab35e72ef2aa8b4e",
      "b82f32acc0e34817b539772eb99c93db",
      "257c0073bd554da4a62d677d881cfaf6",
      "a7dbe1cd8cfb4f28acddca8d74ca1632",
      "1ada0a33855841d4a44e25d2044bac7f",
      "5799394f6a6748dca8a243b63778d6e7",
      "b430a856581d49baa2670ddd43e75585",
      "d6b2ff4db3e24ca3a498c05a22a07992",
      "591d156828064f9abb3809d5d2a91e8e",
      "b7fcd05095ea47c493974858c533fd78",
      "d273a021401549daa0a88feab524e9ac",
      "f1cd49fbfa234aaca0ba72c10de11564",
      "d1a3ee07f0c84862abe982bf33d4bd9f",
      "f4683aa5669447508f90b1118d4b24bf",
      "b852d6d5ffd940a1a57f1877e05f5d85",
      "65851070a1e74c409b0507d795c19961",
      "610f27c6e3c54960bcd63dbba98b1e12",
      "702e04b5793c4ea89af2d5e5f79f444d",
      "a04c35c7e9d14004832ef5a846112c9b",
      "9b2fb340139149d4855d4ade4fecff3f",
      "933fcccce2b74d8ea046263178545d37",
      "aa02ac007cff4dac9e6a17794d080ab4",
      "dbb22636f12542ea842470df6f521e3e",
      "814636c75a934696b8193deb36eb3477",
      "1e747e5376d84b89ada41aaf0ae72feb",
      "3fad17cbc23a48c9bdd482aa5e4d10d2",
      "1adf519c15464f09b6212f5d24652a0e",
      "75f270bfec6f4da3a75e0f9ccfab5887",
      "d9b9716c44d24bbe9e5d1c78cc73c846",
      "d9b89b198f484884964f81c618686e68",
      "8a99526963ce40379bbcc3054e079d92",
      "d23d325cad29409d979c7be642ddacb3",
      "348623fb608e4e3486c4243c73fbcbad",
      "1fce9a973eba4e32aefd4390f9e9d164",
      "d0caae23235d457e97473b2e4e3d0def",
      "f68ec80a953f4779ac92495d2c48c4ad",
      "e4a6b4b5f6354ab8af1a4d7519ceeb56",
      "8b9656eb50bc4375b91d4f22afcb6c87",
      "ae852f082f8b4753a89b886651d8c00f",
      "6d65e80a7d4f4976840d78d3a28fcd66",
      "e01366e2f7f744aa93eb5d833eefea6c",
      "f729d265759e4cf285b5b8f66eeb2010",
      "b881faf675824c308a2d3a6bbd5bae06",
      "982865cf269349758d00084e53d80e06",
      "378ecb86d8524a1ab2dc3041ea809d5d",
      "560560a6a5364996a1bcb163041f7b4a",
      "334fd556eb3b42839a050aeff9a9e049",
      "139adc05abec49c4bb18c4dca95597d8",
      "d189fd77fb264069bc177e9410451197",
      "fcd5f9b31e354773b417bcb52a1cfcb6",
      "e82e5853dd6b470983321fc1ad4ac87e",
      "2aaa535b18ec4dabb6f5c114a291a9e1",
      "00e2d5bee1944337a425ad444c3ed2f2",
      "cd8d4fb112b34abbb69113cac3d12e9a",
      "919e16ccee93460bb2fe28a08f65fa4a",
      "81f6407d16b440d6928e47477982ad9a",
      "ba7732664b394f57b5ade586eff9dec0",
      "a7a2951d31f94022a2af6bdade610104",
      "961ccfb305cb477fbfcfcbe9a58bb681",
      "bc436512c06343448034d73042d83ac4",
      "2e35dbe1b51d48c6975fc98104068a90",
      "8706444574804770931a0ce8eb3ec358",
      "7ea833103b5b4c889646eddd4910cf15",
      "0b5f1b436d1048ad91b09e058fadfdd1",
      "73ca169892164e3186c44a8f439aabec",
      "65ec1ac9f9dd4aeea61511a89852a865",
      "770ccce3e6614c9ab4a9d8113926c1ba",
      "ad8f800a453b4092a6401610a23595a5",
      "cfde43741f5d42df82602516146bd29f",
      "ff4dbaaf2f7a4fc692c6cb2d6365e433",
      "680b831467dc4178bcee1e0c902db8bc",
      "57b34365f9d84b44890b0cca387ca2e5",
      "931157f4c7d94ef78f88a041af9b931f",
      "276649f8545c4cc097756ee947d3b30f",
      "fb944832f8c444dba3489aa5c4b343eb",
      "8a888532ed724bd89fdbacbaad913a6c",
      "3445fb7fb672446ca5c0b3b3513aab5f",
      "e09afab8aa8d40a3b157adaa48ffcd37",
      "15b7f55df1d449cfa0ae0cd24f2b3fe9",
      "d7d6d60347234d8e932acd7b45320412",
      "6df09b39da114527ac3b9baccfb5e0d7",
      "e528c299ebd24be98be9ec926a0adc13",
      "88385fbd037b412eaecb7e94a7f7d511",
      "50bec8c39e82415591fd6729d94aac14",
      "eab77f61f4d64359ab7bc5e2cae79670"
     ]
    },
    "id": "yYf8qlBqW56z",
    "outputId": "52e7986c-f8c5-4970-e81c-72084d7e0d65"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load the embedding model\n",
    "# 'all-MiniLM-L6-v2' is a fantastic, fast, and small model.\n",
    "# It runs 100% on your local machine.\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# 2. Embed all our chunks\n",
    "# This will take a moment as it \"reads\" and \"understands\" each chunk.\n",
    "chunk_embeddings = model.encode(chunks)\n",
    "\n",
    "print(f\"Shape of our embeddings: {chunk_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259,
     "referenced_widgets": [
      "54512c1ab8eb46949294edd7f91777cc",
      "010f86337c0140d6a9ae2c8951724444",
      "8caec4063cae4506bc46b68f5302ab90",
      "17418f1f165d498591ad5e2ca0aa0365",
      "d3cb26d4fc77430aa9a48a1313e2299c",
      "027eb19b37f84d3d97a05de02850c2dd",
      "5fae422c8ffe495282b42462d0d3469d",
      "ec2737f0d762480d97c9d82aa73cc085",
      "dc3722bb0bdf453bb4b046457d1743e3",
      "e37ba43ec0a54aee975117cf249fd181",
      "bf600859c3e6469eb360c3b9f09f9c9b",
      "724b8ce1d3e9468d9d919cf5b4e35ad4",
      "abd38b74b14b401eb8448b05a58d740e",
      "3a78ab2e64fd4be9af1ac0f2bb07f236",
      "b3029262fda9467486dea688f97409b7",
      "8085c31455e0466aa4f9c944b364d0ac",
      "92ff8b41686c407abb068ab33d659ce3",
      "f6f869e85a0e43229bbad7886ed91b7b",
      "e35c0d2b354b4de780c166e8e646e58a",
      "33e8c3b53c134f11bdc4284ee957af68",
      "0802980588d944f3894d32c9eb6e92ea",
      "0906a9c56e2240a7bd543b117e3cd0ab",
      "c1864f4bfcb1401ca6d6515ef9972c40",
      "dc30f9067ada4486b7b2fee8d527f9ba",
      "5d85a083c5214f68839b9793e8bafbaa",
      "0cdfe06b567d4b0289c1841d0029ce92",
      "7286a1a3698548b1b056dedaa60ad7ad",
      "e757b4bf8ed04c8eaa7e35b289f25e4a",
      "4b610cc7e67e41ce8b80d269458942fb",
      "a82a50fc5be5490fb7665294cffacbd9",
      "3c77bd5a95fc46a39de0a60197c624c7",
      "7119c1da4fef48839bfc2d27db9ec913",
      "4103a5a2736c40d98d0c69ba67f5941c",
      "60dc408c58fd4af99df6bec51c3a7061",
      "9aad8bc7c33f4b8a99bf3175218469c2",
      "d88e2e0ce07a4ff5900aa33cbce820b2",
      "dbf201c54f884daaaceb816414989ba0",
      "aa8a5c13423b4648960c3ef945607777",
      "165ddddacee94167bfefb2de3f561066",
      "c43ed26a5ae848d893cb89c760254554",
      "e6def0eb8abd411ebe84c6025a5a3a70",
      "2f7b3e4aa5de4b4aab793509827ae1b9",
      "6963bc512bc34264aeeeec602bbff724",
      "af6ebe39daeb4c6cbe7dc538f6247c3c",
      "c6c5f783d1f74973a3783b0b0276bea1",
      "2363d42857544349916c024b5a41a937",
      "3111a56f072d40e7b6c7c9c3f4162406",
      "365d4fe2994b4a749b00dbef3fa94fc7",
      "0a09fe708a024f0dbe3907cd7d2224fb",
      "f0283b0de48f4a1ea939b29277ec681f",
      "444259ab3ef442fb8673841107b0e240",
      "33ec3dc92cd74de196c8a82cd8ada68b",
      "c945057f357540b7bb563d3e4bfaecd4",
      "eac016d2a29d42239c917e3873cb3d5a",
      "631f228c08d04de9a68388bf7de1db74",
      "a37ffada63d0461a802ff13eae4de074",
      "6e1881d217c240a08ce19d8bf56c8713",
      "f1e9baf8ad204b6eb735ec83c2c91a4f",
      "32b352fadd7246858f90daefb4bdc519",
      "663768359226478aa9429242ebb28b6c",
      "09add3af39df4f9bb092ba48c56425f2",
      "a3d18163082f459390471a139e076a78",
      "d237702e9b454679b41490ca5876e233",
      "e08da0a3b889486a8dd396b6b32832fa",
      "cc983ac51ff547139c8f367d57dae073",
      "e417d3ac99d04e819062703152d87275",
      "f249ed21eda045f6a64f0ebbe5cf3895",
      "b6671c7f9fcd440bb27f7ef72c47cc77",
      "23e8dabcccb349a9a712bb89f3f21e8f",
      "bc57a999ec104089b73445036404a2cb",
      "e6bb44aa8faa44619fdb0e2d664b975a",
      "964b35fce9b24265959e59c7457f6ebe",
      "09be48bc8c314d3bb8c18718567ab099",
      "b60a50defbe04302935929db93263640",
      "d3eec9bea3324f919e91dc689eeda5f0",
      "539f9def46e64256bfb0b0bd314ca2d8",
      "abf22832d29f4545824a1aa6b2d9665a"
     ]
    },
    "id": "i8CEf6UTXFLI",
    "outputId": "2f434ae0-586e-4eda-f5e9-832d2b254759"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 1. Load a \"Question-Answering\" or \"Text-Generation\" model\n",
    "# We'll use a small, instruction-tuned model from Google.\n",
    "generator = pipeline('text2text-generation', model='google/flan-t5-small')\n",
    "\n",
    "# --- This is our RAG pipeline function ---\n",
    "def answer_question(query):\n",
    "    # 1. RETRIEVE\n",
    "    # Embed the user's query\n",
    "    query_embedding = model.encode([query]).astype('float32')\n",
    "\n",
    "    # Search the FAISS index for the top k (e.g., k=2) most similar chunks\n",
    "    k = 2\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    # Get the actual text chunks from our original 'chunks' list\n",
    "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
    "    context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # 2. AUGMENT\n",
    "    # This is the \"magic prompt.\" We combine the retrieved context\n",
    "    # with the user's query.\n",
    "    prompt_template = f\"\"\"\n",
    "    Answer the following question using *only* the provided context.\n",
    "    If the answer is not in the context, say \"I don't have that information.\"\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. GENERATE\n",
    "    # Feed the augmented prompt to our generative model\n",
    "    answer = generator(prompt_template, max_length=100)\n",
    "    print(f\"--- CONTEXT ---\\n{context}\\n\")\n",
    "    return answer[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "830a92d0",
    "outputId": "cce1b529-c1e5-4c50-f714-88a7c5f999f7"
   },
   "outputs": [],
   "source": [
    "from faiss import IndexFlatL2\n",
    "\n",
    "# 3. Create a FAISS Index\n",
    "# FAISS is a library for efficient similarity search. We'll use\n",
    "# a simple L2 distance (Euclidean distance) index.\n",
    "# The index needs to know the dimension of our embeddings (384 for all-MiniLM-L6-v2)\n",
    "index = IndexFlatL2(chunk_embeddings.shape[1])\n",
    "\n",
    "# Add our embeddings to the index\n",
    "index.add(chunk_embeddings)\n",
    "\n",
    "print(f\"Number of vectors in the index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnKnJv1cXl2g",
    "outputId": "988c5aeb-ad9a-4844-bd54-ee893497c32d"
   },
   "outputs": [],
   "source": [
    "query_1 = \"What is the WFH policy?\"\n",
    "print(f\"Query: {query_1}\")\n",
    "print(f\"Answer: {answer_question(query_1)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9zQkuIfXyR2",
    "outputId": "2610ad5d-d0e3-40ff-adf3-fe81889d4a6a"
   },
   "outputs": [],
   "source": [
    "query_2 = \"What is the company's dental plan?\"\n",
    "print(f\"Query: {query_2}\")\n",
    "print(f\"Answer: {answer_question(query_2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "so1lba-oX_v1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
